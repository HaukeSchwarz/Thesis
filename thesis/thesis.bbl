% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nyt/global//global/global}
    \entry{Barocas2016}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=cb55e045fbd37698b0b60a60b567ab83}{%
           family={Barocas},
           familyi={B\bibinitperiod},
           given={Solon},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a507057780ea66f8ee407163b7cec8ff}{%
           family={Selbst},
           familyi={S\bibinitperiod},
           given={Andrew\bibnamedelima D.},
           giveni={A\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {California Law Review, Inc.}%
      }
      \strng{namehash}{7ed35f883e3f721a6f060536e80d6901}
      \strng{fullhash}{7ed35f883e3f721a6f060536e80d6901}
      \strng{bibnamehash}{7ed35f883e3f721a6f060536e80d6901}
      \strng{authorbibnamehash}{7ed35f883e3f721a6f060536e80d6901}
      \strng{authornamehash}{7ed35f883e3f721a6f060536e80d6901}
      \strng{authorfullhash}{7ed35f883e3f721a6f060536e80d6901}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Advocates of algorithmic techniques like data mining argue that these techniques eliminate human biases from the decision-making process. But an algorithm is only as good as the data it works with. Data is frequently imperfect in ways that allow these algorithms to inherit the prejudices of prior decision makers. In other cases, data may simply reflect the widespread biases that persist in society at large. In still others, data mining can discover surprisingly useful regularities that are really just preexisting patterns of exclusion and inequality. Unthinking reliance on data mining can deny historically disadvantaged and vulnerable groups full participation in society. Worse still, because the resulting discrimination is almost always an unintentional emergent property of the algorithm's use rather than a conscious choice by its programmers, it can be unusually hard to identify the source of the problem or to explain it to a court. This Essay examines these concerns through the lens of American antidiscrimination law—more particularly, through Title VII's prohibition of discrimination in employment. In the absence of a demonstrable intent to discriminate, the best doctrinal hope for data mining's victims would seem to lie in disparate impact doctrine. Case law and the Equal Employment Opportunity Commission's Uniform Guidelines, though, hold that a practice can be justified as a business necessity when its outcomes are predictive of future employment outcomes, and data mining is specifically designed to find such statistical correlations. Unless there is a reasonably practical way to demonstrate that these discoveries are spurious, Title VII would appear to bless its use, even though the correlations it discovers will often reflect historic patterns of prejudice, others' discrimination against members of protected groups, or flaws in the underlying data. Addressing the sources of this unintentional discrimination and remedying the corresponding deficiencies in the law will be difficult technically, difficult legally, and difficult politically. There are a number of practical limits to what can be accomplished computationally. For example, when discrimination occurs because the data being mined is itself a result of past intentional discrimination, there is frequently no obvious method to adjust historical data to rid it of this taint. Corrective measures that alter the results of the data mining after it is complete would tread on legally and politically disputed terrain. These challenges for reform throw into stark relief the tension between the two major theories underlying antidiscrimination law: anticlassification and antisubordination. Finding a solution to big data's disparate impact will require more than best efforts to stamp out prejudice and bias; it will require a wholesale reexamination of the meanings of "discrimination" and "fairness."}
      \field{issn}{0008-1221}
      \field{journaltitle}{California Law Review}
      \field{number}{3}
      \field{title}{Big {Data}'s {Disparate} {Impact}}
      \field{volume}{104}
      \field{year}{2016}
      \field{pages}{671\bibrangedash 732}
      \range{pages}{62}
      \verb{file}
      \verb JSTOR Full Text PDF:https\://www.jstor.org/stable/pdfplus/10.2307/24758720.pdf?acceptTC=true:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.jstor.org/stable/24758720
      \endverb
      \verb{url}
      \verb https://www.jstor.org/stable/24758720
      \endverb
    \endentry
    \entry{BarredoArrieta2020}{article}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=9ac145aec0ff90debeae86e848c9984d}{%
           family={Barredo\bibnamedelima Arrieta},
           familyi={B\bibinitperiod\bibinitdelim A\bibinitperiod},
           given={Alejandro},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f2f49e7916926b46a6555cf86c18c919}{%
           family={Díaz-Rodríguez},
           familyi={D\bibinithyphendelim R\bibinitperiod},
           given={Natalia},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cad385a9bc804164f8a02ca66c24913e}{%
           family={Del\bibnamedelima Ser},
           familyi={D\bibinitperiod\bibinitdelim S\bibinitperiod},
           given={Javier},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eee76618bbe2267980002ac15fc73c9b}{%
           family={Bennetot},
           familyi={B\bibinitperiod},
           given={Adrien},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d79f34727bcbbd23065a0c111485c1b}{%
           family={Tabik},
           familyi={T\bibinitperiod},
           given={Siham},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=43d5191cbb4190664e6dad9d9b27505e}{%
           family={Barbado},
           familyi={B\bibinitperiod},
           given={Alberto},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9e4ae61677cf00f7d16f46e14524ffb7}{%
           family={Garcia},
           familyi={G\bibinitperiod},
           given={Salvador},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c76f24f655d5b4f879a86f8c6971a5f0}{%
           family={Gil-Lopez},
           familyi={G\bibinithyphendelim L\bibinitperiod},
           given={Sergio},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=381bf37312a71cebeee50fc633f67c46}{%
           family={Molina},
           familyi={M\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4ff51a3504ff841d75fa3640a2842bff}{%
           family={Benjamins},
           familyi={B\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4a0c0821a0200d3f23713aa8ea5278dc}{%
           family={Chatila},
           familyi={C\bibinitperiod},
           given={Raja},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9f81f46436ba77791311a5db20ff5c25}{%
           family={Herrera},
           familyi={H\bibinitperiod},
           given={Francisco},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{50f0a58c77869be7e1702c64668d6a08}
      \strng{fullhash}{feb210010afaef788607947cc37ee687}
      \strng{bibnamehash}{50f0a58c77869be7e1702c64668d6a08}
      \strng{authorbibnamehash}{50f0a58c77869be7e1702c64668d6a08}
      \strng{authornamehash}{50f0a58c77869be7e1702c64668d6a08}
      \strng{authorfullhash}{feb210010afaef788607947cc37ee687}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.}
      \field{issn}{1566-2535}
      \field{journaltitle}{Information Fusion}
      \field{month}{6}
      \field{shorttitle}{Explainable {Artificial} {Intelligence} ({XAI})}
      \field{title}{Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}}
      \field{volume}{58}
      \field{year}{2020}
      \field{pages}{82\bibrangedash 115}
      \range{pages}{34}
      \verb{doi}
      \verb 10.1016/j.inffus.2019.12.012
      \endverb
      \verb{file}
      \verb ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/abs/pii/S1566253519308103/pdfft?isDTMRedir=true&download=true:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S1566253519308103
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S1566253519308103
      \endverb
      \keyw{Explainable Artificial Intelligence,Machine Learning,Deep Learning,Data Fusion,Interpretability,Comprehensibility,Transparency,Privacy,Fairness,Accountability,Responsible Artificial Intelligence}
    \endentry
    \entry{Bellamy2019}{article}{}
      \name{author}{18}{}{%
        {{un=0,uniquepart=base,hash=2c87a199f314ba76a8239daa4c5a471d}{%
           family={Bellamy},
           familyi={B\bibinitperiod},
           given={Rachel},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7eea19b60fca70e48c4908d39017a95b}{%
           family={Dey},
           familyi={D\bibinitperiod},
           given={Kuntal},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=79965ab18066c72febb431453b9c5292}{%
           family={Hind},
           familyi={H\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=516336e5ebc498fb1f5c5b3250ed691b}{%
           family={Hoffman},
           familyi={H\bibinitperiod},
           given={Samuel},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dcc9db054b5582c3f6461270ce7082f2}{%
           family={Houde},
           familyi={H\bibinitperiod},
           given={Stephanie},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=144cbdc71137d16c88ce9d1274d4f6b2}{%
           family={Kannan},
           familyi={K\bibinitperiod},
           given={Kalapriya},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=85bc23b42b9358452cdecb08f7df05c1}{%
           family={Lohia},
           familyi={L\bibinitperiod},
           given={Pranay},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ce56ccb78666f0b071d3e9f3bd1456e7}{%
           family={Martino},
           familyi={M\bibinitperiod},
           given={Jacquelyn},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb378fc897441f58f0b87c994b6cf0c3}{%
           family={Mehta},
           familyi={M\bibinitperiod},
           given={Sameep},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5b307172bb37df012d87c57be4d9fa00}{%
           family={Mojsilovic},
           familyi={M\bibinitperiod},
           given={Aleksandra},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4cb3cda6f4874983491dee9b20350d08}{%
           family={Nagar},
           familyi={N\bibinitperiod},
           given={Seema},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b51cb5fad7b85d3305a54e0c5189be2e}{%
           family={Natesan\bibnamedelima Ramamurthy},
           familyi={N\bibinitperiod\bibinitdelim R\bibinitperiod},
           given={Karthikeyan},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a6ce8dfac7bb5c8c619a3476b673cc30}{%
           family={Richards},
           familyi={R\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=aa4c810638779bcdaf224c4e117fc751}{%
           family={Saha},
           familyi={S\bibinitperiod},
           given={Diptikalyan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cee509eae344ced0d8cd625e2e3b4b64}{%
           family={Sattigeri},
           familyi={S\bibinitperiod},
           given={Prasanna},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1400939940f79ddc1fb64bbd1cee0531}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Moninder},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a9c6f8058b0f850d726bece00c6b10e}{%
           family={Varshney},
           familyi={V\bibinitperiod},
           given={Kush},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9912d78ae87e3e4c03aa245499e81f4}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yunfeng},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{0bc101b523e41d4a3933c42655e15c68}
      \strng{fullhash}{ee154f279f2ea4ae67592bd7dc134c98}
      \strng{bibnamehash}{0bc101b523e41d4a3933c42655e15c68}
      \strng{authorbibnamehash}{0bc101b523e41d4a3933c42655e15c68}
      \strng{authornamehash}{0bc101b523e41d4a3933c42655e15c68}
      \strng{authorfullhash}{ee154f279f2ea4ae67592bd7dc134c98}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IBM Journal of Research and Development}
      \field{month}{09}
      \field{title}{AI Fairness 360: An Extensible Toolkit for Detecting and Mitigating Algorithmic Bias}
      \field{volume}{PP}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 1}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1147/JRD.2019.2942287
      \endverb
    \endentry
    \entry{Bhutta2022}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=7a62444d1a4a95bd1e1d35864402d3ad}{%
           family={Bhutta},
           familyi={B\bibinitperiod},
           given={Neil},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=baafda717c1906b89c1256ef937ef96d}{%
           family={Hizmo},
           familyi={H\bibinitperiod},
           given={Aurel},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a55508a6fdcfca533d582131e1ca2608}{%
           family={Ringo},
           familyi={R\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{3a025acab95632eecbfd397b7c68ba87}
      \strng{fullhash}{d8fcfbc18b94a5b6300b54cb7a808ff0}
      \strng{bibnamehash}{d8fcfbc18b94a5b6300b54cb7a808ff0}
      \strng{authorbibnamehash}{d8fcfbc18b94a5b6300b54cb7a808ff0}
      \strng{authornamehash}{3a025acab95632eecbfd397b7c68ba87}
      \strng{authorfullhash}{d8fcfbc18b94a5b6300b54cb7a808ff0}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The Federal Reserve Board of Governors in Washington DC.}
      \field{month}{10}
      \field{shorttitle}{How {Much} {Does} {Racial} {Bias} {Affect} {Mortgage} {Lending}?}
      \field{title}{How {Much} {Does} {Racial} {Bias} {Affect} {Mortgage} {Lending}? {Evidence} from {Human} and {Algorithmic} {Credit} {Decisions}}
      \field{urlday}{27}
      \field{urlmonth}{2}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb :Bhutta2022 - How Much Does Racial Bias Affect Mortgage Lending_ Evidence from Human and Algorithmic Credit Decisions.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://www.federalreserve.gov/econres/feds/how-much-does-racial-bias-affect-mortgage-lending.htm
      \endverb
      \verb{url}
      \verb https://www.federalreserve.gov/econres/feds/how-much-does-racial-bias-affect-mortgage-lending.htm
      \endverb
    \endentry
    \entry{Burrell2016}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=e4fb32e340f29cc5617fb36a94abe804}{%
           family={Burrell},
           familyi={B\bibinitperiod},
           given={Jenna},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {SAGE Publications Ltd}%
      }
      \strng{namehash}{e4fb32e340f29cc5617fb36a94abe804}
      \strng{fullhash}{e4fb32e340f29cc5617fb36a94abe804}
      \strng{bibnamehash}{e4fb32e340f29cc5617fb36a94abe804}
      \strng{authorbibnamehash}{e4fb32e340f29cc5617fb36a94abe804}
      \strng{authornamehash}{e4fb32e340f29cc5617fb36a94abe804}
      \strng{authorfullhash}{e4fb32e340f29cc5617fb36a94abe804}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm.}
      \field{issn}{2053-9517}
      \field{journaltitle}{Big Data \& Society}
      \field{month}{6}
      \field{number}{1}
      \field{shorttitle}{How the machine ‘thinks’}
      \field{title}{How the machine ‘thinks’: {Understanding} opacity in machine learning algorithms}
      \field{volume}{3}
      \field{year}{2016}
      \verb{doi}
      \verb 10.1177/2053951715622512
      \endverb
      \verb{file}
      \verb SAGE PDF Full Text:https\://journals.sagepub.com/doi/pdf/10.1177/2053951715622512:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1177/2053951715622512
      \endverb
      \verb{url}
      \verb https://doi.org/10.1177/2053951715622512
      \endverb
    \endentry
    \entry{Calmon2017}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=fcfdc520c2a8b14267c762cab48878b0}{%
           family={Calmon},
           familyi={C\bibinitperiod},
           given={Flavio},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f3792e697ba7dd59bb280735cfe39079}{%
           family={Wei},
           familyi={W\bibinitperiod},
           given={Dennis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e10e6b267b3663d628cdd7147a06674a}{%
           family={Vinzamuri},
           familyi={V\bibinitperiod},
           given={Bhanukiran},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b51cb5fad7b85d3305a54e0c5189be2e}{%
           family={Natesan\bibnamedelima Ramamurthy},
           familyi={N\bibinitperiod\bibinitdelim R\bibinitperiod},
           given={Karthikeyan},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6ee022cf13c12a788da92b67a9780cff}{%
           family={Varshney},
           familyi={V\bibinitperiod},
           given={Kush\bibnamedelima R},
           giveni={K\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{7}{}{%
        {{hash=e7e74de725116358b68a6e890c026145}{%
           family={Guyon},
           familyi={G\bibinitperiod},
           given={I.},
           giveni={I\bibinitperiod}}}%
        {{hash=3b118a9660c18913c6d05d3bcfae41a3}{%
           family={Luxburg},
           familyi={L\bibinitperiod},
           given={U.\bibnamedelimi Von},
           giveni={U\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{hash=9b411b6c9cefdde16ffea77ecf612142}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=1444141e07dd9549dbb4b8530fe4ec15}{%
           family={Wallach},
           familyi={W\bibinitperiod},
           given={H.},
           giveni={H\bibinitperiod}}}%
        {{hash=f3857e15544199442f3d4fb2cf6645b4}{%
           family={Fergus},
           familyi={F\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
        {{hash=c73f06e2fc98c9b0bf52eb5fdce61943}{%
           family={Vishwanathan},
           familyi={V\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=36b98b7ab533936cf1b5716148de704f}{%
           family={Garnett},
           familyi={G\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{c5d89c8095ac422421c5889f45a88c6d}
      \strng{fullhash}{7a0db0ff3c5818ce4fcc6fbdef7dec5a}
      \strng{bibnamehash}{c5d89c8095ac422421c5889f45a88c6d}
      \strng{authorbibnamehash}{c5d89c8095ac422421c5889f45a88c6d}
      \strng{authornamehash}{c5d89c8095ac422421c5889f45a88c6d}
      \strng{authorfullhash}{7a0db0ff3c5818ce4fcc6fbdef7dec5a}
      \strng{editorbibnamehash}{7cffda9a379be8eb9063eee4eb0f58b3}
      \strng{editornamehash}{7cffda9a379be8eb9063eee4eb0f58b3}
      \strng{editorfullhash}{1564f811a39f09a7400a11284c987926}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Advances in Neural Information Processing Systems}
      \field{title}{Optimized Pre-Processing for Discrimination Prevention}
      \field{volume}{30}
      \field{year}{2017}
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper_files/paper/2017/file/9a49a25d845a483fae4be7e341368e36-Paper.pdf
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper_files/paper/2017/file/9a49a25d845a483fae4be7e341368e36-Paper.pdf
      \endverb
    \endentry
    \entry{Caruana2015}{inproceedings}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=599c5251d489b92dc7856277d56cb1a9}{%
           family={Caruana},
           familyi={C\bibinitperiod},
           given={Rich},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=67f76e36e64df182b735da0440c35b84}{%
           family={Lou},
           familyi={L\bibinitperiod},
           given={Yin},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89173e109d33053942397c24c048f5c2}{%
           family={Gehrke},
           familyi={G\bibinitperiod},
           given={Johannes},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=703e065f6602a496e08abb38d20c02d2}{%
           family={Koch},
           familyi={K\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=379e8db35785ea22547a6cad6cc6265c}{%
           family={Sturm},
           familyi={S\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3be880e08d80db7febe6076f8af50f90}{%
           family={Elhadad},
           familyi={E\bibinitperiod},
           given={Noemie},
           giveni={N\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{089af20c0e85c71235697709555dc96d}
      \strng{fullhash}{5b15957286a84b00cf808e153a4fe128}
      \strng{bibnamehash}{089af20c0e85c71235697709555dc96d}
      \strng{authorbibnamehash}{089af20c0e85c71235697709555dc96d}
      \strng{authornamehash}{089af20c0e85c71235697709555dc96d}
      \strng{authorfullhash}{5b15957286a84b00cf808e153a4fe128}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In machine learning often a tradeoff must be made between accuracy and intelligibility. More accurate models such as boosted trees, random forests, and neural nets usually are not intelligible, but more intelligible models such as logistic regression, naive-Bayes, and single decision trees often have significantly worse accuracy. This tradeoff sometimes limits the accuracy of models that can be applied in mission-critical applications such as healthcare where being able to understand, validate, edit, and trust a learned model is important. We present two case studies where high-performance generalized additive models with pairwise interactions (GA2Ms) are applied to real healthcare problems yielding intelligible models with state-of-the-art accuracy. In the pneumonia risk prediction case study, the intelligible model uncovers surprising patterns in the data that previously had prevented complex learned models from being fielded in this domain, but because it is intelligible and modular allows these patterns to be recognized and removed. In the 30-day hospital readmission case study, we show that the same methods scale to large datasets containing hundreds of thousands of patients and thousands of attributes while remaining intelligible and providing accuracy comparable to the best (unintelligible) machine learning methods.}
      \field{booktitle}{Proceedings of the 21th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}}
      \field{isbn}{9781450336642}
      \field{month}{8}
      \field{series}{{KDD} '15}
      \field{shorttitle}{Intelligible {Models} for {HealthCare}}
      \field{title}{Intelligible {Models} for {HealthCare}: {Predicting} {Pneumonia} {Risk} and {Hospital} 30-day {Readmission}}
      \field{year}{2015}
      \field{pages}{1721\bibrangedash 1730}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2783258.2788613
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2783258.2788613
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2783258.2788613
      \endverb
      \keyw{additive models,classification,healthcare,intelligibility,interaction detection,logistic regression,risk prediction}
    \endentry
    \entry{Chen2019}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=69bd6c70a08a67d2841abb1b24a5ccfa}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Jiahao},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=05588c281fb0ad5fdec0154c3cba1b22}{%
           family={Mao},
           familyi={M\bibinitperiod},
           given={Xiaojie},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7b8405f96b0ca67a22f45bce6c98a9d3}{%
           family={Svacha},
           familyi={S\bibinitperiod},
           given={Geoffry},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8fb06ee4839e284f359c2733a642ce8d}{%
           family={Udell},
           familyi={U\bibinitperiod},
           given={Madeleine},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Atlanta, GA, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b41cb43b730c4a1d59c2729b1efde3f6}
      \strng{fullhash}{0a0f88bde9c30ad66b2e0814809f9c87}
      \strng{bibnamehash}{b41cb43b730c4a1d59c2729b1efde3f6}
      \strng{authorbibnamehash}{b41cb43b730c4a1d59c2729b1efde3f6}
      \strng{authornamehash}{b41cb43b730c4a1d59c2729b1efde3f6}
      \strng{authorfullhash}{0a0f88bde9c30ad66b2e0814809f9c87}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Assessing the fairness of a decision making system with respect to a protected class, such as gender or race, is challenging when class membership labels are unavailable. Probabilistic models for predicting the protected class based on observable proxies, such as surname and geolocation for race, are sometimes used to impute these missing labels for compliance assessments. Empirically, these methods are observed to exaggerate disparities, but the reason why is unknown. In this paper, we decompose the biases in estimating outcome disparity via threshold-based imputation into multiple interpretable bias sources, allowing us to explain when over- or underestimation occurs. We also propose an alternative weighted estimator that uses soft classification, and show that its bias arises simply from the conditional covariance of the outcome with the true class membership. Finally, we illustrate our results with numerical simulations and a public dataset of mortgage applications, using geolocation as a proxy for race. We confirm that the bias of threshold-based imputation is generally upward, but its magnitude varies strongly with the threshold chosen. Our new weighted estimator tends to have a negative bias that is much simpler to analyze and reason about.}
      \field{booktitle}{Proceedings of the Conference on Fairness, Accountability, and Transparency}
      \field{isbn}{9781450361255}
      \field{series}{FAT* '19}
      \field{title}{Fairness Under Unawareness: Assessing Disparity When Protected Class Is Unobserved}
      \field{year}{2019}
      \field{pages}{339\bibrangedash 348}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3287560.3287594
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3287560.3287594
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3287560.3287594
      \endverb
      \keyw{Bayesian Improved Surname Geocoding,disparate impact,fair lending,probablistic proxy model,protected class,race imputation,racial discrimination}
    \endentry
    \entry{Alessandro2017}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=acb904779b7c0a2a2cb560f566b410e2}{%
           family={d'Alessandro},
           familyi={d\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2d9e8c54407ca5f4ae5ce79112bcffdf}{%
           family={O'Neil},
           familyi={O\bibinitperiod},
           given={Cathy},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f27fc2679610ebc8ff2ea289315e6041}{%
           family={LaGatta},
           familyi={L\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8ae7b66b87653b4f0e7456d4485bbe32}
      \strng{fullhash}{c7ec3bfec92805aa1f7a1d407068f988}
      \strng{bibnamehash}{c7ec3bfec92805aa1f7a1d407068f988}
      \strng{authorbibnamehash}{c7ec3bfec92805aa1f7a1d407068f988}
      \strng{authornamehash}{8ae7b66b87653b4f0e7456d4485bbe32}
      \strng{authorfullhash}{c7ec3bfec92805aa1f7a1d407068f988}
      \field{sortinit}{d}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Big Data}
      \field{month}{06}
      \field{title}{Conscientious Classification: A Data Scientist's Guide to Discrimination-Aware Classification}
      \field{volume}{5}
      \field{year}{2017}
      \field{pages}{120\bibrangedash 134}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1089/big.2016.0048
      \endverb
    \endentry
    \entry{Datta2017}{report}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=c3ec74f0096bebfca003e01940429056}{%
           family={Datta},
           familyi={D\bibinitperiod},
           given={Anupam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ca53191803a563335db0f1917ff556b2}{%
           family={Fredrikson},
           familyi={F\bibinitperiod},
           given={Matt},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=13b7b28318c3c0bd6c6fa7e42e215645}{%
           family={Ko},
           familyi={K\bibinitperiod},
           given={Gihyuk},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=36b04db0da7f3f385e92a82ac5ba3937}{%
           family={Mardziel},
           familyi={M\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3678cc10aee52aba805deb8794de560}{%
           family={Sen},
           familyi={S\bibinitperiod},
           given={Shayak},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {arXiv}%
      }
      \strng{namehash}{087dd7e9663a31bdd9758941644f1493}
      \strng{fullhash}{8d9383cac9da3b5cfba50c6e235a91b4}
      \strng{bibnamehash}{087dd7e9663a31bdd9758941644f1493}
      \strng{authorbibnamehash}{087dd7e9663a31bdd9758941644f1493}
      \strng{authornamehash}{087dd7e9663a31bdd9758941644f1493}
      \strng{authorfullhash}{8d9383cac9da3b5cfba50c6e235a91b4}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Machine learnt systems inherit biases against protected classes, historically disparaged groups, from training data. Usually, these biases are not explicit, they rely on subtle correlations discovered by training algorithms, and are therefore difficult to detect. We formalize proxy discrimination in data-driven systems, a class of properties indicative of bias, as the presence of protected class correlates that have causal influence on the system's output. We evaluate an implementation on a corpus of social datasets, demonstrating how to validate systems against these properties and to repair violations where they occur.}
      \field{annotation}{Comment: arXiv admin note: substantial text overlap with arXiv:1705.07807}
      \field{month}{7}
      \field{note}{arXiv:1707.08120 [cs] type: article}
      \field{title}{Proxy {Non}-{Discrimination} in {Data}-{Driven} {Systems}}
      \field{type}{techreport}
      \field{year}{2017}
      \verb{doi}
      \verb 10.48550/arXiv.1707.08120
      \endverb
      \verb{file}
      \verb :Datta2017 - Proxy Non Discrimination in Data Driven Systems.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1707.08120
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1707.08120
      \endverb
      \keyw{Computer Science - Computers and Society,Computer Science - Machine Learning}
    \endentry
    \entry{DoshiVelez2017}{report}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=b01a5e92cd39a5551d74ab2393c7b9fd}{%
           family={Doshi-Velez},
           familyi={D\bibinithyphendelim V\bibinitperiod},
           given={Finale},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a11a6718c039f3e3f3f31167e5094c10}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Been},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {arXiv}%
      }
      \strng{namehash}{66c38242b4ecdd0e74f6a1fb48199a21}
      \strng{fullhash}{66c38242b4ecdd0e74f6a1fb48199a21}
      \strng{bibnamehash}{66c38242b4ecdd0e74f6a1fb48199a21}
      \strng{authorbibnamehash}{66c38242b4ecdd0e74f6a1fb48199a21}
      \strng{authornamehash}{66c38242b4ecdd0e74f6a1fb48199a21}
      \strng{authorfullhash}{66c38242b4ecdd0e74f6a1fb48199a21}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.}
      \field{month}{3}
      \field{note}{arXiv:1702.08608 [cs, stat] type: article}
      \field{title}{Towards {A} {Rigorous} {Science} of {Interpretable} {Machine} {Learning}}
      \field{type}{techreport}
      \field{year}{2017}
      \verb{doi}
      \verb 10.48550/arXiv.1702.08608
      \endverb
      \verb{file}
      \verb :DoshiVelez2017 - Towards a Rigorous Science of Interpretable Machine Learning.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1702.08608
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1702.08608
      \endverb
      \keyw{Statistics - Machine Learning,Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{Feldman2015}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=244c96635798701847a1e6c990863733}{%
           family={Feldman},
           familyi={F\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b2b40e7a0fdfbdbcf9af2da7c8e59417}{%
           family={Friedler},
           familyi={F\bibinitperiod},
           given={Sorelle\bibnamedelima A.},
           giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2dfff61dbc9e69984218b6fa859febd5}{%
           family={Moeller},
           familyi={M\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de216a4cef9daa2d1fce563e8b498941}{%
           family={Scheidegger},
           familyi={S\bibinitperiod},
           given={Carlos},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=aaeb9142f2e1590450061f637edb6845}{%
           family={Venkatasubramanian},
           familyi={V\bibinitperiod},
           given={Suresh},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Sydney, NSW, Australia}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{3b1cce86496aaf13c09dd79ffe2475b2}
      \strng{fullhash}{1ece2bf8f6d5dee69a99b249fc47c0ce}
      \strng{bibnamehash}{3b1cce86496aaf13c09dd79ffe2475b2}
      \strng{authorbibnamehash}{3b1cce86496aaf13c09dd79ffe2475b2}
      \strng{authornamehash}{3b1cce86496aaf13c09dd79ffe2475b2}
      \strng{authorfullhash}{1ece2bf8f6d5dee69a99b249fc47c0ce}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{What does it mean for an algorithm to be biased? In U.S. law, unintentional bias is encoded via disparate impact, which occurs when a selection process has widely different outcomes for different groups, even as it appears to be neutral. This legal determination hinges on a definition of a protected class (ethnicity, gender) and an explicit description of the process.When computers are involved, determining disparate impact (and hence bias) is harder. It might not be possible to disclose the process. In addition, even if the process is open, it might be hard to elucidate in a legal setting how the algorithm makes its decisions. Instead of requiring access to the process, we propose making inferences based on the data it uses.We present four contributions. First, we link disparate impact to a measure of classification accuracy that while known, has received relatively little attention. Second, we propose a test for disparate impact based on how well the protected class can be predicted from the other attributes. Third, we describe methods by which data might be made unbiased. Finally, we present empirical evidence supporting the effectiveness of our test for disparate impact and our approach for both masking bias and preserving relevant information in the data. Interestingly, our approach resembles some actual selection practices that have recently received legal scrutiny.}
      \field{booktitle}{Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}
      \field{isbn}{9781450336642}
      \field{series}{KDD '15}
      \field{title}{Certifying and Removing Disparate Impact}
      \field{year}{2015}
      \field{pages}{259\bibrangedash 268}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2783258.2783311
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2783258.2783311
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2783258.2783311
      \endverb
      \keyw{machine learning,fairness,disparate impact}
    \endentry
    \entry{Guidotti2018}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=da8fc5161754b324b4ac06cdfcb9f51e}{%
           family={Guidotti},
           familyi={G\bibinitperiod},
           given={Riccardo},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2b005cc0cd264224d2555c63a72d798d}{%
           family={Monreale},
           familyi={M\bibinitperiod},
           given={Anna},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a76ccbef49119aa2cc87d46090bea705}{%
           family={Ruggieri},
           familyi={R\bibinitperiod},
           given={Salvatore},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=239ddb34b2b1f4cba06ecb606fca3560}{%
           family={Turini},
           familyi={T\bibinitperiod},
           given={Franco},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7b5335e9010800b63f5c2959f076d90f}{%
           family={Giannotti},
           familyi={G\bibinitperiod},
           given={Fosca},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a2cc2c3b41c34d28b00e8b61bf830b42}{%
           family={Pedreschi},
           familyi={P\bibinitperiod},
           given={Dino},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{82f290714ed3cfe5fe35f2e58678f788}
      \strng{fullhash}{3579dc0dfeb86c4d5f58a6a93ec112a3}
      \strng{bibnamehash}{82f290714ed3cfe5fe35f2e58678f788}
      \strng{authorbibnamehash}{82f290714ed3cfe5fe35f2e58678f788}
      \strng{authornamehash}{82f290714ed3cfe5fe35f2e58678f788}
      \strng{authorfullhash}{3579dc0dfeb86c4d5f58a6a93ec112a3}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.}
      \field{issn}{0360-0300}
      \field{journaltitle}{ACM Computing Surveys}
      \field{month}{8}
      \field{number}{5}
      \field{title}{A {Survey} of {Methods} for {Explaining} {Black} {Box} {Models}}
      \field{volume}{51}
      \field{year}{2018}
      \field{pages}{93:1\bibrangedash 93:42}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1145/3236009
      \endverb
      \verb{file}
      \verb :Guidotti2018 - A Survey of Methods for Explaining Black Box Models.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/1802.01933
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/1802.01933
      \endverb
      \keyw{Open the black box,explanations,interpretability,transparent models}
    \endentry
    \entry{Gunning2019}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=25d2cc74dc187d8b48d08bbdae1064da}{%
           family={Gunning},
           familyi={G\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=92a14ac89f93c224dc339aaaa178fd94}{%
           family={Aha},
           familyi={A\bibinitperiod},
           given={David\bibnamedelima W.},
           giveni={D\bibinitperiod\bibinitdelim W\bibinitperiod},
           givenun=0}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{1ceffbc2ab77c147b9f7a988e25a52db}
      \strng{fullhash}{1ceffbc2ab77c147b9f7a988e25a52db}
      \strng{bibnamehash}{1ceffbc2ab77c147b9f7a988e25a52db}
      \strng{authorbibnamehash}{1ceffbc2ab77c147b9f7a988e25a52db}
      \strng{authornamehash}{1ceffbc2ab77c147b9f7a988e25a52db}
      \strng{authorfullhash}{1ceffbc2ab77c147b9f7a988e25a52db}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Dramatic success in machine learning has led to a new wave of AI applications (for example, transportation, security, medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA's explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. The XAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human-computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4-year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems' explanations improve user understanding, user trust, and user task performance.}
      \field{issn}{2371-9621}
      \field{journaltitle}{AI Magazine}
      \field{number}{2}
      \field{title}{{DARPA}'s {Explainable} {Artificial} {Intelligence} {Program}}
      \field{volume}{40}
      \field{year}{2019}
      \field{pages}{44\bibrangedash 58}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1609/aimag.v40i2.2850
      \endverb
      \verb{file}
      \verb Full Text PDF:https\://onlinelibrary.wiley.com/doi/pdfdirect/10.1609/aimag.v40i2.2850:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1609/aimag.v40i2.2850
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1609/aimag.v40i2.2850
      \endverb
    \endentry
    \entry{Hardt2016}{report}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=e771760b6d0d33f8b4dfd907d8d57ac2}{%
           family={Hardt},
           familyi={H\bibinitperiod},
           given={Moritz},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b0b481f252064438215c11421a5d102f}{%
           family={Price},
           familyi={P\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4a4fc057d8331655775a21a8994f3339}{%
           family={Srebro},
           familyi={S\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6715d12818335ad532b3aa871d63dcdf}
      \strng{fullhash}{fd6cdc27517719fbf581f97eb68c5bb0}
      \strng{bibnamehash}{fd6cdc27517719fbf581f97eb68c5bb0}
      \strng{authorbibnamehash}{fd6cdc27517719fbf581f97eb68c5bb0}
      \strng{authornamehash}{6715d12818335ad532b3aa871d63dcdf}
      \strng{authorfullhash}{fd6cdc27517719fbf581f97eb68c5bb0}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. We illustrate our notion using a case study of FICO credit scores.}
      \field{month}{10}
      \field{note}{arXiv:1610.02413 [cs] type: article}
      \field{title}{Equality of {Opportunity} in {Supervised} {Learning}}
      \field{type}{techreport}
      \field{year}{2016}
      \verb{doi}
      \verb 10.48550/arXiv.1610.02413
      \endverb
      \verb{file}
      \verb :Hardt2016 - Equality of Opportunity in Supervised Learning.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1610.02413
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1610.02413
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{Kamiran2012}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=767ab6888ee1d3aa5cdc53f783d7d4e1}{%
           family={Kamiran},
           familyi={K\bibinitperiod},
           given={Faisal},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6aab2f9608a64a01a7cdd6501ba9fd5c}{%
           family={Calders},
           familyi={C\bibinitperiod},
           given={Toon},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{65e3c39300f08d29f99407c58fb60d14}
      \strng{fullhash}{65e3c39300f08d29f99407c58fb60d14}
      \strng{bibnamehash}{65e3c39300f08d29f99407c58fb60d14}
      \strng{authorbibnamehash}{65e3c39300f08d29f99407c58fb60d14}
      \strng{authornamehash}{65e3c39300f08d29f99407c58fb60d14}
      \strng{authorfullhash}{65e3c39300f08d29f99407c58fb60d14}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, the following Discrimination-Aware Classification Problem was introduced: Suppose we are given training data that exhibit unlawful discrimination; e.g., toward sensitive attributes such as gender or ethnicity. The task is to learn a classifier that optimizes accuracy, but does not have this discrimination in its predictions on test data. This problem is relevant in many settings, such as when the data are generated by a biased decision process or when the sensitive attribute serves as a proxy for unobserved features. In this paper, we concentrate on the case with only one binary sensitive attribute and a two-class classification problem. We first study the theoretically optimal trade-off between accuracy and non-discrimination for pure classifiers. Then, we look at algorithmic solutions that preprocess the data to remove discrimination before a classifier is learned. We survey and extend our existing data preprocessing techniques, being suppression of the sensitive attribute, massaging the dataset by changing class labels, and reweighing or resampling the data to remove discrimination without relabeling instances. These preprocessing techniques have been implemented in a modified version of Weka and we present the results of experiments on real-life data.}
      \field{issn}{0219-3116}
      \field{journaltitle}{Knowledge and Information Systems}
      \field{month}{10}
      \field{number}{1}
      \field{title}{Data preprocessing techniques for classification without discrimination}
      \field{volume}{33}
      \field{year}{2012}
      \field{pages}{1\bibrangedash 33}
      \range{pages}{33}
      \verb{doi}
      \verb 10.1007/s10115-011-0463-8
      \endverb
      \verb{file}
      \verb :Kamiran2012 - Data Preprocessing Techniques for Classification without Discrimination.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s10115-011-0463-8
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s10115-011-0463-8
      \endverb
      \keyw{Classification,Preprocessing,Discrimination-aware data mining}
    \endentry
    \entry{Kamishima2012}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=deda01c09bf5becd0c4d49b99fd0c096}{%
           family={Kamishima},
           familyi={K\bibinitperiod},
           given={Toshihiro},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=688fc78f0fdd83d6a6a087950cfcdd3f}{%
           family={Akaho},
           familyi={A\bibinitperiod},
           given={Shotaro},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ff2e29c565fa4cc865595ea1636f716e}{%
           family={Asoh},
           familyi={A\bibinitperiod},
           given={Hideki},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e50997be633aa84a225f937f2e76437e}{%
           family={Sakuma},
           familyi={S\bibinitperiod},
           given={Jun},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{3}{}{%
        {{hash=396f43e4116eb90951c1b3c963d1501a}{%
           family={Flach},
           familyi={F\bibinitperiod},
           given={Peter\bibnamedelima A.},
           giveni={P\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=c0da3cbd10c1e5cf6d9fac513267fe8e}{%
           family={De\bibnamedelima Bie},
           familyi={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           given={Tijl},
           giveni={T\bibinitperiod}}}%
        {{hash=b643588b4a53ed47702d3277b6de83a9}{%
           family={Cristianini},
           familyi={C\bibinitperiod},
           given={Nello},
           giveni={N\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{23eee66c64cc9f2da18753269b1c3859}
      \strng{fullhash}{d10e331baf9e1205b368922e4f60b347}
      \strng{bibnamehash}{23eee66c64cc9f2da18753269b1c3859}
      \strng{authorbibnamehash}{23eee66c64cc9f2da18753269b1c3859}
      \strng{authornamehash}{23eee66c64cc9f2da18753269b1c3859}
      \strng{authorfullhash}{d10e331baf9e1205b368922e4f60b347}
      \strng{editorbibnamehash}{1035364434bb4a118fee07fedce98389}
      \strng{editornamehash}{2706b10f1098b788befac885d812cd68}
      \strng{editorfullhash}{1035364434bb4a118fee07fedce98389}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the spread of data mining technologies and the accumulation of social data, such technologies and data are being used for determinations that seriously affect individuals' lives. For example, credit scoring is frequently determined based on the records of past credit data together with statistical prediction techniques. Needless to say, such determinations must be nondiscriminatory and fair in sensitive features, such as race, gender, religion, and so on. Several researchers have recently begun to attempt the development of analysis techniques that are aware of social fairness or discrimination. They have shown that simply avoiding the use of sensitive features is insufficient for eliminating biases in determinations, due to the indirect influence of sensitive information. In this paper, we first discuss three causes of unfairness in machine learning. We then propose a regularization approach that is applicable to any prediction algorithm with probabilistic discriminative models. We further apply this approach to logistic regression and empirically show its effectiveness and efficiency.}
      \field{booktitle}{Machine Learning and Knowledge Discovery in Databases}
      \field{isbn}{978-3-642-33486-3}
      \field{title}{Fairness-Aware Classifier with Prejudice Remover Regularizer}
      \field{year}{2012}
      \field{pages}{35\bibrangedash 50}
      \range{pages}{16}
    \endentry
    \entry{Kim2016}{inproceedings}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=a11a6718c039f3e3f3f31167e5094c10}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Been},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a3d9b23b97482af55601d7db22cbf99e}{%
           family={Khanna},
           familyi={K\bibinitperiod},
           given={Rajiv},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0feb43ba975fb91c3f51303c882e958}{%
           family={Koyejo},
           familyi={K\bibinitperiod},
           given={Oluwasanmi\bibnamedelima O},
           giveni={O\bibinitperiod\bibinitdelim O\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{5}{}{%
        {{hash=98056d9ddecda0076a31a183e3e69326}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={D.},
           giveni={D\bibinitperiod}}}%
        {{hash=0ef91066dee98e654f9aebd57da00647}{%
           family={Sugiyama},
           familyi={S\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=24a834b722f8b79357bd16d08a1e523f}{%
           family={Luxburg},
           familyi={L\bibinitperiod},
           given={U.},
           giveni={U\bibinitperiod}}}%
        {{hash=e7e74de725116358b68a6e890c026145}{%
           family={Guyon},
           familyi={G\bibinitperiod},
           given={I.},
           giveni={I\bibinitperiod}}}%
        {{hash=36b98b7ab533936cf1b5716148de704f}{%
           family={Garnett},
           familyi={G\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{754b02892648bfc2c99a6c9e7bdfc2dc}
      \strng{fullhash}{dda8cded8fcfe731c78054018e04d61e}
      \strng{bibnamehash}{dda8cded8fcfe731c78054018e04d61e}
      \strng{authorbibnamehash}{dda8cded8fcfe731c78054018e04d61e}
      \strng{authornamehash}{754b02892648bfc2c99a6c9e7bdfc2dc}
      \strng{authorfullhash}{dda8cded8fcfe731c78054018e04d61e}
      \strng{editorbibnamehash}{a39670f7069dc3237dbc92fe523ad0c6}
      \strng{editornamehash}{a39670f7069dc3237dbc92fe523ad0c6}
      \strng{editorfullhash}{12a698699c223bd18ce3abc205938f9b}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Advances in Neural Information Processing Systems}
      \field{title}{Examples are not enough, learn to criticize! Criticism for Interpretability}
      \field{volume}{29}
      \field{year}{2016}
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper_files/paper/2016/file/5680522b8e2bb01943234bce7bf84534-Paper.pdf
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper_files/paper/2016/file/5680522b8e2bb01943234bce7bf84534-Paper.pdf
      \endverb
    \endentry
    \entry{Linardatos2021}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=b1cb6820f7c44b05374180a54934adb3}{%
           family={Linardatos},
           familyi={L\bibinitperiod},
           given={Pantelis},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ed990d467a87c96a07f652b55ec62716}{%
           family={Papastefanopoulos},
           familyi={P\bibinitperiod},
           given={Vasilis},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=455d9b7c9c8ff82a0a3673712365237c}{%
           family={Kotsiantis},
           familyi={K\bibinitperiod},
           given={Sotiris},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {Multidisciplinary Digital Publishing Institute}%
      }
      \strng{namehash}{dbfc091863c2007d665e2e8fa59e8f72}
      \strng{fullhash}{fd919348aa5487733a9ac23ee49c0eaa}
      \strng{bibnamehash}{fd919348aa5487733a9ac23ee49c0eaa}
      \strng{authorbibnamehash}{fd919348aa5487733a9ac23ee49c0eaa}
      \strng{authornamehash}{dbfc091863c2007d665e2e8fa59e8f72}
      \strng{authorfullhash}{fd919348aa5487733a9ac23ee49c0eaa}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into “black box” approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.}
      \field{issn}{1099-4300}
      \field{journaltitle}{Entropy}
      \field{month}{1}
      \field{number}{1}
      \field{shorttitle}{Explainable {AI}}
      \field{title}{Explainable {AI}: {A} {Review} of {Machine} {Learning} {Interpretability} {Methods}}
      \field{volume}{23}
      \field{year}{2021}
      \field{pages}{18}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/e23010018
      \endverb
      \verb{file}
      \verb :Linardatos2021 - Explainable AI_ a Review of Machine Learning Interpretability Methods.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1099-4300/23/1/18
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1099-4300/23/1/18
      \endverb
      \keyw{xai,machine learning,explainability,interpretability,fairness,sensitivity,black-box}
    \endentry
    \entry{Lipton2018}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=599ae457cf41d4ce64e09433edbc964b}{%
           family={Lipton},
           familyi={L\bibinitperiod},
           given={Zachary\bibnamedelima C.},
           giveni={Z\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{599ae457cf41d4ce64e09433edbc964b}
      \strng{fullhash}{599ae457cf41d4ce64e09433edbc964b}
      \strng{bibnamehash}{599ae457cf41d4ce64e09433edbc964b}
      \strng{authorbibnamehash}{599ae457cf41d4ce64e09433edbc964b}
      \strng{authornamehash}{599ae457cf41d4ce64e09433edbc964b}
      \strng{authorfullhash}{599ae457cf41d4ce64e09433edbc964b}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Supervised machine-learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world?}
      \field{issn}{1542-7730}
      \field{journaltitle}{Queue}
      \field{month}{6}
      \field{number}{3}
      \field{shorttitle}{The {Mythos} of {Model} {Interpretability}}
      \field{title}{The {Mythos} of {Model} {Interpretability}: {In} machine learning, the concept of interpretability is both important and slippery.}
      \field{urlday}{18}
      \field{urlmonth}{2}
      \field{urlyear}{2024}
      \field{volume}{16}
      \field{year}{2018}
      \field{urldateera}{ce}
      \field{pages}{31\bibrangedash 57}
      \range{pages}{27}
      \verb{doi}
      \verb 10.1145/3236386.3241340
      \endverb
      \verb{file}
      \verb :Lipton2018 - The Mythos of Model Interpretability_ in Machine Learning, the Concept of Interpretability Is Both Important and Slippery..pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/1606.03490
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/1606.03490
      \endverb
    \endentry
    \entry{Marcinkevics2023}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=68ed0731fd5b9f5c6cc8035be131eb5a}{%
           family={Marcinkevičs},
           familyi={M\bibinitperiod},
           given={Ričards},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=76b8207b3e792705bd59adc14f399702}{%
           family={Vogt},
           familyi={V\bibinitperiod},
           given={Julia\bibnamedelima E.},
           giveni={J\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{ee49f13b1bf4b79e647e8d3ce0d3c807}
      \strng{fullhash}{ee49f13b1bf4b79e647e8d3ce0d3c807}
      \strng{bibnamehash}{ee49f13b1bf4b79e647e8d3ce0d3c807}
      \strng{authorbibnamehash}{ee49f13b1bf4b79e647e8d3ce0d3c807}
      \strng{authornamehash}{ee49f13b1bf4b79e647e8d3ce0d3c807}
      \strng{authorfullhash}{ee49f13b1bf4b79e647e8d3ce0d3c807}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Interpretability and explainability are crucial for machine learning (ML) and statistical applications in medicine, economics, law, and natural sciences and form an essential principle for ML model design and development. Although interpretability and explainability have escaped a precise and universal definition, many models and techniques motivated by these properties have been developed over the last 30 years, with the focus currently shifting toward deep learning. We will consider concrete examples of state-of-the-art, including specially tailored rule-based, sparse, and additive classification models, interpretable representation learning, and methods for explaining black-box models post hoc. The discussion will emphasize the need for and relevance of interpretability and explainability, the divide between them, and the inductive biases behind the presented “zoo” of interpretable models and explanation methods. This article is categorized under: Fundamental Concepts of Data and Knowledge {>} Explainable AI Technologies {>} Machine Learning Commercial, Legal, and Ethical Issues {>} Social Considerations}
      \field{issn}{1942-4795}
      \field{journaltitle}{WIREs Data Mining and Knowledge Discovery}
      \field{number}{3}
      \field{shorttitle}{Interpretable and explainable machine learning}
      \field{title}{Interpretable and explainable machine learning: {A} methods-centric overview with concrete examples}
      \field{volume}{13}
      \field{year}{2023}
      \field{pages}{e1493}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1002/widm.1493
      \endverb
      \verb{file}
      \verb Full Text PDF:https\://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/widm.1493:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1493
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1493
      \endverb
      \keyw{explainability,interpretability,machine learning,neural networks}
    \endentry
    \entry{Mehrabi2021}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=e49a830517defa430474d9c2b5c22d83}{%
           family={Mehrabi},
           familyi={M\bibinitperiod},
           given={Ninareh},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6fc2e21e9c786462d54f7e2eeae61c19}{%
           family={Morstatter},
           familyi={M\bibinitperiod},
           given={Fred},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=125158a659e4885af8901c5155a4e57a}{%
           family={Saxena},
           familyi={S\bibinitperiod},
           given={Nripsuta},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8aea0a421db201a447f5fec22e73a92f}{%
           family={Lerman},
           familyi={L\bibinitperiod},
           given={Kristina},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=73b781905368dfe2cc66cef5e33e0d32}{%
           family={Galstyan},
           familyi={G\bibinitperiod},
           given={Aram},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{cc037d6c925e3502b4bada6900e5b052}
      \strng{fullhash}{70df8b815290d4668300a842f0dfe8bc}
      \strng{bibnamehash}{cc037d6c925e3502b4bada6900e5b052}
      \strng{authorbibnamehash}{cc037d6c925e3502b4bada6900e5b052}
      \strng{authornamehash}{cc037d6c925e3502b4bada6900e5b052}
      \strng{authorfullhash}{70df8b815290d4668300a842f0dfe8bc}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.}
      \field{issn}{0360-0300}
      \field{journaltitle}{ACM Computing Surveys}
      \field{month}{7}
      \field{number}{6}
      \field{title}{A {Survey} on {Bias} and {Fairness} in {Machine} {Learning}}
      \field{volume}{54}
      \field{year}{2021}
      \field{pages}{115:1\bibrangedash 115:35}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1145/3457607
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/1908.09635
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/1908.09635
      \endverb
      \keyw{Fairness and bias in artificial intelligence,deep learning,machine learning,natural language processing,representation learning}
    \endentry
    \entry{Murdoch2019}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=22c46697552a85457f5d2a862a502350}{%
           family={Murdoch},
           familyi={M\bibinitperiod},
           given={W.\bibnamedelimi James},
           giveni={W\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d46196fdd4e251f39ed2cc52b0308d4b}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Chandan},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=13e53b7130829772308671d8809a92f2}{%
           family={Kumbier},
           familyi={K\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=31d85fc904c5901571f1ff0edcd3bf80}{%
           family={Abbasi-Asl},
           familyi={A\bibinithyphendelim A\bibinitperiod},
           given={Reza},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=43d22dc81cc0e5bb1d24d5eeb65ecbae}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Bin},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Proceedings of the National Academy of Sciences}%
      }
      \strng{namehash}{37d6aee03aa03f5d5b08353bc019e388}
      \strng{fullhash}{b044182d5bd267eb97319fc6439993ff}
      \strng{bibnamehash}{37d6aee03aa03f5d5b08353bc019e388}
      \strng{authorbibnamehash}{37d6aee03aa03f5d5b08353bc019e388}
      \strng{authornamehash}{37d6aee03aa03f5d5b08353bc019e388}
      \strng{authorfullhash}{b044182d5bd267eb97319fc6439993ff}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.}
      \field{journaltitle}{Proceedings of the National Academy of Sciences}
      \field{month}{10}
      \field{number}{44}
      \field{title}{Definitions, methods, and applications in interpretable machine learning}
      \field{volume}{116}
      \field{year}{2019}
      \verb{doi}
      \verb 10.1073/pnas.1900654116
      \endverb
      \verb{file}
      \verb Full Text PDF:https\://www.pnas.org/doi/pdf/10.1073/pnas.1900654116:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.pnas.org/doi/full/10.1073/pnas.1900654116
      \endverb
      \verb{url}
      \verb https://www.pnas.org/doi/full/10.1073/pnas.1900654116
      \endverb
    \endentry
    \entry{Deepak2021}{inproceedings}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=1836ce1e72a133641077f8df764789c8}{%
           family={Padmanabhan},
           familyi={P\bibinitperiod},
           given={Deepak},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5a8e383aea76d211f65c09e8fbc3ae15}{%
           family={V.},
           familyi={V\bibinitperiod},
           given={Sanil},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dba8def2ab0a49708369b9f1f7d76058}{%
           family={Jose},
           familyi={J\bibinitperiod},
           given={Joemon\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{56153477f5fec4ea5bac48f685da486a}
      \strng{fullhash}{6492cebc58e541c37d55636791537110}
      \strng{bibnamehash}{6492cebc58e541c37d55636791537110}
      \strng{authorbibnamehash}{6492cebc58e541c37d55636791537110}
      \strng{authornamehash}{56153477f5fec4ea5bac48f685da486a}
      \strng{authorfullhash}{6492cebc58e541c37d55636791537110}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Ethical AI spans a gamut of considerations. Among these, the most popular ones, fairness and interpretability, have remained largely distinct in technical pursuits. We discuss and elucidate the differences between fairness and interpretability across a variety of dimensions. Further, we develop two principles-based frameworks towards develop- ing ethical AI for the future that embrace aspects of both fairness and interpretability. First, interpretability for fairness proposes instantiating interpretability within the realm of fairness to develop a new breed of ethical AI. Second, fairness and interpretability initiates deliberations on bringing the best aspects of both together. We hope that these two frameworks will contribute to intensify- ing scholarly discussions on new frontiers of ethical AI that brings together fairness and interpretability.}
      \field{booktitle}{IJCAI 2021 Workshop on AI for Social Good}
      \field{title}{On Fairness and Interpretability}
      \field{year}{2021}
    \endentry
    \entry{Pessach2020}{report}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=99ed2bd5cd96edde9caf52fb2c97436b}{%
           family={Pessach},
           familyi={P\bibinitperiod},
           given={Dana},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=85b1412798ce5a7ef782f040faf8203a}{%
           family={Shmueli},
           familyi={S\bibinitperiod},
           given={Erez},
           giveni={E\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b41653466fc0a0a322220b9f30889060}
      \strng{fullhash}{b41653466fc0a0a322220b9f30889060}
      \strng{bibnamehash}{b41653466fc0a0a322220b9f30889060}
      \strng{authorbibnamehash}{b41653466fc0a0a322220b9f30889060}
      \strng{authornamehash}{b41653466fc0a0a322220b9f30889060}
      \strng{authorfullhash}{b41653466fc0a0a322220b9f30889060}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence (AI) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop AI algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision-making may be inherently prone to unfairness, even when there is no intention for it. This paper presents an overview of the main concepts of identifying, measuring and improving algorithmic fairness when using AI algorithms. The paper begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, towards a better understanding of which mechanisms should be used in different scenarios. The paper then describes the most commonly used fairness-related datasets in this field. Finally, the paper ends by reviewing several emerging research sub-fields of algorithmic fairness.}
      \field{annotation}{Comment: 31 pages, 1 figure, This is a survey article that reviews the field of algorithmic fairness}
      \field{month}{1}
      \field{note}{arXiv:2001.09784 [cs, stat] type: article}
      \field{title}{Algorithmic {Fairness}}
      \field{type}{techreport}
      \field{year}{2020}
      \verb{doi}
      \verb 10.48550/arXiv.2001.09784
      \endverb
      \verb{file}
      \verb :Pessach2020 - Algorithmic Fairness.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2001.09784
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2001.09784
      \endverb
      \keyw{Computer Science - Computers and Society,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{Pradhan2022}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=f871c8118d77327419b7e6292833d8c8}{%
           family={Pradhan},
           familyi={P\bibinitperiod},
           given={Romila},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b6d7fd0cdbde3459a802ba434d76692a}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Jiongli},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=43da5c7ddcb78da27cf5011a21ea2fd4}{%
           family={Glavic},
           familyi={G\bibinitperiod},
           given={Boris},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=866f58f5d1eeb1664972e51e9fa9671a}{%
           family={Salimi},
           familyi={S\bibinitperiod},
           given={Babak},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b30ae51ad467a0735c1f12b78b8ef5ba}
      \strng{fullhash}{f51511dc80dce357312442b4d77e6f8e}
      \strng{bibnamehash}{b30ae51ad467a0735c1f12b78b8ef5ba}
      \strng{authorbibnamehash}{b30ae51ad467a0735c1f12b78b8ef5ba}
      \strng{authornamehash}{b30ae51ad467a0735c1f12b78b8ef5ba}
      \strng{authorfullhash}{f51511dc80dce357312442b4d77e6f8e}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A wide variety of fairness metrics and eXplainable Artificial Intelligence (XAI) approaches have been proposed in the literature to identify bias in machine learning models that are used in critical real-life contexts. However, merely reporting on a model's bias or generating explanations using existing XAI techniques is insufficient to locate and eventually mitigate sources of bias. We introduce Gopher, a system that produces compact, interpretable, and causal explanations for bias or unexpected model behavior by identifying coherent subsets of the training data that are root-causes for this behavior. Specifically, we introduce the concept of causal responsibility that quantifies the extent to which intervening on training data by removing or updating subsets of it can resolve the bias. Building on this concept, we develop an efficient approach for generating the top-k patterns that explain model bias by utilizing techniques from the machine learning (ML) community to approximate causal responsibility, and using pruning rules to manage the large search space for patterns. Our experimental evaluation demonstrates the effectiveness of Gopher in generating interpretable explanations for identifying and debugging sources of bias.}
      \field{booktitle}{Proceedings of the 2022 {International} {Conference} on {Management} of {Data}}
      \field{isbn}{9781450392495}
      \field{month}{6}
      \field{series}{{SIGMOD} '22}
      \field{title}{Interpretable {Data}-{Based} {Explanations} for {Fairness} {Debugging}}
      \field{year}{2022}
      \field{pages}{247\bibrangedash 261}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1145/3514221.3517886
      \endverb
      \verb{file}
      \verb :Pradhan2022 - Interpretable Data Based Explanations for Fairness Debugging.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://dl.acm.org/doi/10.1145/3514221.3517886
      \endverb
      \verb{url}
      \verb https://dl.acm.org/doi/10.1145/3514221.3517886
      \endverb
      \keyw{data debugging,explanations,fairness,interpretability}
    \endentry
    \entry{GDPR}{misc}{}
      \list{language}{1}{%
        {en}%
      }
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{url}
      \field{labeltitlesource}{title}
      \field{title}{Regulation - 2016/679 - {EN} - gdpr - {EUR}-{Lex}}
      \field{urlday}{18}
      \field{urlmonth}{2}
      \field{urlyear}{2024}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://eur-lex.europa.eu/eli/reg/2016/679/oj
      \endverb
      \verb{url}
      \verb https://eur-lex.europa.eu/eli/reg/2016/679/oj
      \endverb
    \endentry
    \entry{Teodorescu2020}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=dfca41496df1723708b63f6c908fb0b8}{%
           family={Teodorescu},
           familyi={T\bibinitperiod},
           given={Mike\bibnamedelima Horia},
           giveni={M\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e9b1abc57a612fc5afcc19b1ae98efeb}{%
           family={Morse},
           familyi={M\bibinitperiod},
           given={Lily},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=988cafdfe82a19d9a62590ec30e5d172}{%
           family={Awwad},
           familyi={A\bibinitperiod},
           given={Yazeed},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b30587ecfa545f70cc8dfdf47d2dfe9a}{%
           family={Kane},
           familyi={K\bibinitperiod},
           given={Jerry},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Academy of Management}%
      }
      \strng{namehash}{5ee5d180478d70cc92e7630fe763e03b}
      \strng{fullhash}{d8ca741d818da796cf79b0f0106c704f}
      \strng{bibnamehash}{5ee5d180478d70cc92e7630fe763e03b}
      \strng{authorbibnamehash}{5ee5d180478d70cc92e7630fe763e03b}
      \strng{authornamehash}{5ee5d180478d70cc92e7630fe763e03b}
      \strng{authorfullhash}{d8ca741d818da796cf79b0f0106c704f}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The use of machine learning in organizations presents a double-edged sword: machine learning tools reduce costs on otherwise repetitive, time-consuming tasks, yet run the risks of introducing systematic unfairness in organizational processes. Issues of behavioral ethics in machine learning implementations in organizations have not been thoroughly addressed in prior literature, as many of the necessary concepts are disparate across three literatures – ethics, machine learning, and management. Further, tradeoffs between fairness criteria in machine learning have not been addressed with regards to organizations. We move research forward by introducing an organizing framework for selecting and implementing fair algorithms in organizations."}
      \field{issn}{0065-0668}
      \field{journaltitle}{Academy of Management Proceedings}
      \field{month}{8}
      \field{number}{1}
      \field{title}{A {Framework} for {Fairer} {Machine} {Learning} in {Organizations}}
      \field{volume}{2020}
      \field{year}{2020}
      \field{pages}{16889}
      \range{pages}{1}
      \verb{doi}
      \verb 10.5465/AMBPP.2020.16889abstract
      \endverb
      \verb{file}
      \verb :C\:/Users/Hauke/OneDrive - ucp.pt/04_Thesis/01_Material/02_Other/Morse et al._A Framework for Fairer Machine Learning in Organizations.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://journals.aom.org/doi/10.5465/AMBPP.2020.16889abstract
      \endverb
      \verb{url}
      \verb https://journals.aom.org/doi/10.5465/AMBPP.2020.16889abstract
      \endverb
      \keyw{AOM Annual Meeting Proceedings 2020}
    \endentry
    \entry{Zafar2017}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=651ed744d2d757bbdb4ef8519fdb9745}{%
           family={Zafar},
           familyi={Z\bibinitperiod},
           given={Muhammad\bibnamedelima Bilal},
           giveni={M\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=86077c699c3bcb4f9fecce395f1e6f41}{%
           family={Valera},
           familyi={V\bibinitperiod},
           given={Isabel},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=58d0e095ee85f537d94f11a32509a911}{%
           family={Rogriguez},
           familyi={R\bibinitperiod},
           given={Manuel\bibnamedelima Gomez},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dbf52af009e972037dc69055660e4a65}{%
           family={Gummadi},
           familyi={G\bibinitperiod},
           given={Krishna\bibnamedelima P.},
           giveni={K\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{2}{}{%
        {{hash=d77c73a14b0f048484c1d34aba3071d4}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Aarti},
           giveni={A\bibinitperiod}}}%
        {{hash=39c902c926e80826b55032878c4a4b49}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Jerry},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {PMLR}%
      }
      \strng{namehash}{5a3b59ce7c7b687c4ebf7f069fab18c2}
      \strng{fullhash}{8cf94f95ed5c2ba94c905031b07c4686}
      \strng{bibnamehash}{5a3b59ce7c7b687c4ebf7f069fab18c2}
      \strng{authorbibnamehash}{5a3b59ce7c7b687c4ebf7f069fab18c2}
      \strng{authornamehash}{5a3b59ce7c7b687c4ebf7f069fab18c2}
      \strng{authorfullhash}{8cf94f95ed5c2ba94c905031b07c4686}
      \strng{editorbibnamehash}{76ce338934df3b777883645db0b56555}
      \strng{editornamehash}{76ce338934df3b777883645db0b56555}
      \strng{editorfullhash}{76ce338934df3b777883645db0b56555}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Algorithmic decision making systems are ubiquitous across a wide variety of online as well as offline services. These systems rely on complex learning methods and vast amounts of data to optimize the service functionality, satisfaction of the end user and profitability. However, there is a growing concern that these automated decisions can lead, even in the absence of intent, to a lack of fairness, i.e., their outcomes can disproportionately hurt (or, benefit) particular groups of people sharing one or more sensitive attributes (e.g., race, sex). In this paper, we introduce a flexible mechanism to design fair classifiers by leveraging a novel intuitive measure of decision boundary (un)fairness. We instantiate this mechanism with two well-known classifiers, logistic regression and support vector machines, and show on real-world data that our mechanism allows for a fine-grained control on the degree of fairness, often at a small cost in terms of accuracy.}
      \field{booktitle}{Proceedings of the 20th International Conference on Artificial Intelligence and Statistics}
      \field{month}{20--22 Apr}
      \field{series}{Proceedings of Machine Learning Research}
      \field{title}{{Fairness Constraints: Mechanisms for Fair Classification}}
      \field{volume}{54}
      \field{year}{2017}
      \field{pages}{962\bibrangedash 970}
      \range{pages}{9}
      \verb{file}
      \verb http://proceedings.mlr.press/v54/zafar17a/zafar17a.pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v54/zafar17a.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v54/zafar17a.html
      \endverb
    \endentry
    \entry{Zhou2022}{inbook}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=e15b17db828c6a6aba1c93445356b44d}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Jianlong},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5de529f763fe493fc1be5a3fa71d53d}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Fang},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3f4842b3f24d20f809775dbf780810ab}{%
           family={Holzinger},
           familyi={H\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{6}{}{%
        {{hash=3f4842b3f24d20f809775dbf780810ab}{%
           family={Holzinger},
           familyi={H\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
        {{hash=67d0e7c2f3249b72cf5c5efc1a6c8fbd}{%
           family={Goebel},
           familyi={G\bibinitperiod},
           given={Randy},
           giveni={R\bibinitperiod}}}%
        {{hash=68863d44ca413f278c0bdf0cf1aa096a}{%
           family={Fong},
           familyi={F\bibinitperiod},
           given={Ruth},
           giveni={R\bibinitperiod}}}%
        {{hash=5af6d4a3072af3ffed619eac87fc7a80}{%
           family={Moon},
           familyi={M\bibinitperiod},
           given={Taesup},
           giveni={T\bibinitperiod}}}%
        {{hash=9f1b6144a45b1967e989e74552e37ada}{%
           family={Müller},
           familyi={M\bibinitperiod},
           given={Klaus-Robert},
           giveni={K\bibinithyphendelim R\bibinitperiod}}}%
        {{hash=7f49b6382ab4ca917a2aa2249f875f79}{%
           family={Samek},
           familyi={S\bibinitperiod},
           given={Wojciech},
           giveni={W\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{2cf8281c4000d47d3dbf00f1bd115e69}
      \strng{fullhash}{5556b77d305265e3b98632a412e625f2}
      \strng{bibnamehash}{5556b77d305265e3b98632a412e625f2}
      \strng{authorbibnamehash}{5556b77d305265e3b98632a412e625f2}
      \strng{authornamehash}{2cf8281c4000d47d3dbf00f1bd115e69}
      \strng{authorfullhash}{5556b77d305265e3b98632a412e625f2}
      \strng{editorbibnamehash}{24c8392c3e894cc00d04bfd3c472917e}
      \strng{editornamehash}{24c8392c3e894cc00d04bfd3c472917e}
      \strng{editorfullhash}{232716a8903bf664a6e79cf511a69008}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{AI explainability is becoming indispensable to allow users to gain insights into the AI system's decision-making process. Meanwhile, fairness is another rising concern that algorithmic predictions may be misaligned to the designer's intent or social expectations such as discrimination to specific groups. In this work, we provide a state-of-the-art overview on the relations between explanation and AI fairness and especially the roles of explanation on human's fairness judgement. The investigations demonstrate that fair decision making requires extensive contextual understanding, and AI explanations help identify potential variables that are driving the unfair outcomes. It is found that different types of AI explanations affect human's fairness judgements differently. Some properties of features and social science theories need to be considered in making senses of fairness with explanations. Different challenges are identified to make responsible AI for trustworthy decision making from the perspective of explainability and fairness.}
      \field{booktitle}{xxAI - Beyond Explainable AI: International Workshop, Held in Conjunction with ICML 2020, July 18, 2020, Vienna, Austria, Revised and Extended Papers}
      \field{isbn}{978-3-031-04083-2}
      \field{title}{Towards Explainability for AI Fairness}
      \field{year}{2022}
      \field{pages}{375\bibrangedash 386}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1007/978-3-031-04083-2_18
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/978-3-031-04083-2_18
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/978-3-031-04083-2_18
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

