\chapter{Results}\label{chap:Results}

% Update?
% In this chapter, the results of the analysis are presented. \textbf{Chapter \ref{sec:Exploratory_Data_Analysis}} provides an overview of the data and explores the fairness of the dataset. 
% \textbf{Chapter \ref{sec:Results}} presents the results of the analysis. \textbf{Chapter \ref{sec:Limitations}} discusses the limitations of the analysis.

\section{Exploratory Data Analysis}\label{sec:Exploratory_Data_Analysis}

\subsection{Data Overview}\label{subsec:Data_Overview}

The processed dataset contained two \textit{numerical} features: \textbf{interest\_rate} and \textbf{loan\_to\_value\_ratio}.
Their distributions can be seen in \textbf{Figure \ref{fig:CHXX_Numerical_Distributions_1}} and \textbf{Figure \ref{fig:CHXX_Numerical_Distributions_2}}.
Both are positively correlated with a correlation coefficient of \textit{0.54}. 

\begin{figure}[h]
    \centering
    \caption{Boxplots of the Numerical Features}
    \includegraphics[width=0.85\textwidth]{CHXX_Numerical_Distributions_1.png}
    \caption*{The results of the KNNImputer applying mean (annotated in red) values for all missing values show clearly here by the narrow quartiles.}
    \label{fig:CHXX_Numerical_Distributions_1}
\end{figure}

\begin{figure}[h]
    \centering
    \caption{Histograms of the Numerical Features}
    \includegraphics[width=0.85\textwidth]{CHXX_Numerical_Distributions_2.png}
    \caption*{The results of the KNNImputer applying mean (annotated in red) values for all missing values show clearly here by the high amount of values at the mean.}
    \label{fig:CHXX_Numerical_Distributions_2}
\end{figure}

Exploratory data analysis of the categorical variables (XXX Detail in appendix and referral here XXX) showed that the majority of loan applicants are \textbf{White} (65\%) and \textbf{Male} (85\%), resulting in 57\% of all applicants being both White and Male.
Most loans applied for are \textbf{Conventional} (82\%) and \textbf{First Lien} (86\%).
Aside from missingness in the \textit{debt\_to\_income\_ratio} feature, which alone accounts for 26\% of all values, the data in this feature are roughly normally distributed, with the mode being 14\% of values in the \textbf{36\%-41\%} range. 

\subsection{Fairness}\label{subsec:Fairness}

Following the scope of this thesis specified in \textbf{chapter \ref{ch:Introduction}}, a special needs to be put focus on fairness, specifically equality with regards to the protected attribute(s).
This potential unfairness in the underlying data can be identified from assessing the distribution of the target variable across different groups.
\textbf{Figure \ref{fig:CHXX_Loan_Grant_By_Protected_Attribute}} shows the amount of (not) granted loans per race and by sex, the probabilities of being granted a loan across these groups can be found in \textbf{Table \ref{tab:loan_granting}}.\@

\begin{figure}[h]
    \centering
    \caption{Loan Grant by Protected Attribute}
    \includegraphics[width=0.85\textwidth]{CHXX_Loan_Grant_By_Protected_Attribute.png}
    \caption*{Discrimination by race is apparent in the data, as the amount of granted loans differs significantly}
    \label{fig:CHXX_Loan_Grant_By_Protected_Attribute}
\end{figure}

\begin{table}[htbp]
    \centering
      \caption{Loan Granting Statistics by Applicant Race and Sex}
      \begin{tabular}{lcc}
      \toprule
      \textbf{Applicant Race} & \textbf{Applicant Sex} & \textbf{Loan Granted (\%)} \\
      \midrule
      Black or African American & Male    & 46.4 \\
            & Female  & 44.1 \\
      White & Male    & 60.9 \\
            & Female  & 58.8 \\
      \bottomrule
      \end{tabular}
      \caption*{Regardless of their gender, Black or African American applicants are less likely to be granted a loan than White applicants.}
    \label{tab:loan_granting}%
\end{table}%

Even though the focus of the analysis is on the \textit{applicant\_race-1} attribute, \textit{applicant\_sex} has been included as a second discriminating factor, as it also constitutes a protected attribute.
Inspection of the results depicted here did however imply that the issue of racial equality is more pronounced than that of inequality between the sexes.
A chi-squared test of independence proved that assumption of underlying inequality between races in the data, as the p-value is \textit{<0.01} and therefore H0 (equality in granted loans) could be rejected at any significance level.
Utilizing the aforementioned \textbf{AIF360} package to assess the mean difference of granted loans between the races in the underlying data amounted to a \textit{14.9\%} difference.

\subsection{Enrichment Data}\label{subsec:Enrichment_Data}

As stated before, analyzing the geographical information provided in the enrichment dataset (see \textbf{chapter \ref{subsec:Enrichment_Data_Methodology}} and \textbf{chapter \ref{subsec:Enrichment_Data}}) was expected to provide additional insights into the fairness of the model.
A sign of potential discrimination in the data could be the correlation between race and potentially favorable outcomes, such as a higher percentage of granted loans or a lower poverty rate.
\textbf{Figure \ref{fig:Scatter_White_Applicants_Loan_Grant}} shows a scatterplot that relates the percentage of white applicants to the percentage of granted loans per county. It indicates that a higher percentage of white applicants per county does not only seem to be correlated with a higher percentage of these loans actually being granted, but also with a lower poverty rate on average.

\begin{figure}[h]
    \centering
    \caption{Relationship between Applicant Race, Poverty Rate and Loan Grants}
    \includegraphics[width=0.85\textwidth]{images/CHXX_Perc_Grants_vs_Perc_White.png}
    \caption*{Counties with predominantly White applicants do not only tend to have a lower poverty rate on average, but also see a higher percentage of loans being granted on average.}
    \label{fig:Scatter_White_Applicants_Loan_Grant}
\end{figure}

It should however be noted that the distributions within the enrichment data themselves are skewed by nature, as there are way higher numbers of White applicants in the data set and only few counties have a substantial number of predicted mortgage grants (see \textbf{Figure \ref{fig:Enrichment_Data_EDA}}).

\begin{figure}[h]
    \centering
    \caption{Enrichment Data EDA}
    \begin{minipage}{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/geo_enrich/predictions_per_county.png}
    \end{minipage}\hfill
    \begin{minipage}{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/geo_enrich/perc_predictions.png}
    \end{minipage}\hfill
    \begin{minipage}{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/geo_enrich/white_per_county.png}
    \end{minipage}\hfill
    \label{fig:Enrichment_Data_EDA}
    \caption*{Analyzing the enrichment data shows that while the percentage of predictions per county appears to be normally distributed, the distributions of the percentage of White applicants and the percentage of predicted granted loans per county are skewed.}
\end{figure}


\section{Results}\label{sec:Results}        

As defined in \textbf{chapter \ref{subsec:Performance_Assessment}} and \textbf{chapter \ref{subsec:Fairness_Assessment}}, each outcome is assessed in terms of performance and fairness with two pre-defined metric sets. Additionally, the aspect of Explainability will be demonstrated examplarily for the initial model run.

\subsection{Initial Performance}\label{subsec:Initial_Performance}

The initial run serving as a benchmark was conducted training the neural network described in \textbf{chapter \ref{subsec:Model_Training_and_Prediction}} on the unadjusted training data (see \textbf{chapter \ref{subsec:HMDA_Data}}).

\textbf{Explainability}

As was intended in \textbf{chapter \ref{subsec:Explainability}}, three different Explainability algorithms were utilized to challenge each other's results and analyze overall patterns. \textbf{Figure \ref{fig:SHAP_explanations}} and \textbf{Figure \ref{fig:LIME_explanations}} show the individual explanations for the first 150 observations of the test set provided by SHAP and LIME, respectively. 
As already mentioned in \textbf{Chapter \ref{subsec:Performance_Assessment}}, the model behaved somewhat different from the expectations: Imputation of missing values in the \textit{debt\_to\_income\_ratio} feature led to a significant decrease in both fairness and performance measures of the model.
Therefore, it must be assumed that missingness in itself is not completely at random and holds information (or that the imputation method via a random forest regressor is not suitable for this task).
While SHAP considers that missingness to be the most important influence on model predictions, LIME weighs the \textit{debt\_to\_income\_ratio} features higher in general.
None of the algorithms consider the protected attributes to be of high direct impact on the results.

\begin{figure}[h]
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/CHXX_UPDATE_SHAP_individual.png}
        \caption{SHAP individual explanations}
        \label{fig:SHAP_explanations}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/CHXX_UPDATE_LIME_individual.png}
        \caption{LIME individual explanations}
        \label{fig:LIME_explanations}
    \end{minipage}
    \caption*{Directly comparing LIME and SHAP explanations for the first 150 observations of the test set: While \textit{debt\_to\_income\_ratio} is an important factor in both explanations, its actual impact varies, as LIME also considers the \textit{loan\_type} feature to be of high importance. Default plotting options were kept: SHAP values are displayed as absolutes, while LIME values show the direction of their impact.}
\end{figure}

While the overall trends are similar with both algorithms, the actual impact of the features varies significantly. While this is not a direct threat to the quality of the results of this thesis, it is a reminder that Explainability algorithms need to be analyzed carefully. 
This ties with the findings of Krishna et al. \parencite{Krishna2022}, who emphasize the importance of understanding the underlying assumptions of Explainability algorithms and the need for a more comprehensive evaluation of their results.

To validate the results of the local explanations, a \textit{Global Surrogate Model} was used. \textbf{Figure \ref{fig:Global_Surrogate}} shows the results of the global surrogate model. Specifically, the five most important features according to the global surrogate model are compared to the SHAP and LIME explanations in terms of their relative performance.
It is apparent that the overall trends of SHAP and LIME are close to the global explanations.

\begin{figure}[h]
    \centering
    \caption{Global Surrogate Model compared to SHAP and LIME}
    \includegraphics[width=0.85\textwidth]{images/CHXX_UPDATE_Surrogate_SHAP_LIME_combined.png}
    \caption*{Analyzing the 5 most important features according to the global surrogate model implies that the overall trends of SHAP and LIME are close to the global explanations.}
    \label{fig:Global_Surrogate}
\end{figure}

\textbf{Performance}

Even without directly comparable benchmarks available (see \textbf{chapter \ref{subsec:Performance_Assessment}}), the initial model performance can be considered as good. Details can be found in \textbf{table \ref{tab:initial_model_performance_results_1}}.

\begin{table}[h]
    \centering
    \caption{Metrics \#1: Initial Model}
    \begin{tabular}{l c}
    \toprule
    \textbf{Metric} & \textbf{Value} \\
    \midrule
    \textbf{accuracy} & 0.90 \\
    \textbf{precision} & 0.88 \\
    \textbf{recall} & 0.96 \\
    \textbf{f1} & 0.92 \\
    \textbf{roc\_auc} & 0.94 \\
    \bottomrule
    \end{tabular}
    \caption*{The initial model shows a high accuracy and recall, but a lower precision and f1 score. The overall performance can be considered good.}
    \label{tab:initial_model_performance_results_1}
\end{table}

\textbf{Fairness}

\textbf{Table \ref{tab:initial_model_fairness_results_1}} shows the results of the fairness assessment of the initial model. The disparities in the true positive rate and false positive rate are relatively low, while the disparities in the true negative rate and false negative rate are higher.

\begin{table}[h]
    \caption{Metrics \#2: Initial Model}
    \begin{minipage}[t]{0.5\textwidth}
    \centering
    \begin{tabular}{lr}
    \toprule
    \textbf{Metric} & \textbf{Value} \\
    \midrule
    \textbf{Accuracy White} & 0.91 \\
    \textbf{Precision White} & 0.89 \\
    \textbf{Recall White} & 0.97 \\
    \textbf{F1 Score White} & 0.93 \\
    \textbf{AUC White} & 0.94 \\
    \textbf{Accuracy Black} & 0.89 \\
    \textbf{Precision Black} & 0.84 \\
    \textbf{Recall Black} & 0.92 \\
    \textbf{F1 Score Black} & 0.88 \\
    \textbf{AUC Black} & 0.95 \\
    \bottomrule
    \end{tabular}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.5\textwidth}
    \centering
    \begin{tabular}{lr}
    \toprule
    \textbf{Metric} & \textbf{Value} \\
    \midrule
    \textbf{tpr\_disparity} & 0.95 \\
    \textbf{fpr\_disparity} & 0.77 \\
    \textbf{tnr\_disparity} & 1.05 \\
    \textbf{fnr\_disparity} & 2.51 \\
    \bottomrule
    \end{tabular}
    \end{minipage}
    \label{tab:initial_model_fairness_results_1}
    \caption*{The initial model shows a higher accuracy and recall for White applicants, but a higher precision and F1 score for Black applicants. The AUC is higher for Black applicants. The disparities in the true positive rate and false positive rate are relatively low, while the disparities in the true negative rate and false negative rate are higher.}
\end{table}

\subsection{Results of the Iterations}\label{subsec:Iterations}

None of the techniques applied in the iterations led to a significant increase in fairness. The \textit{reweighing} technique managed to improve the overall fairness of the model, but the other techniques did not manage to reach the same level of fairness. 
% The results of the iterations are summarized in \textbf{table \ref{tab:model_performance_fairness_results}} and \textbf{table \ref{tab:subgroup_fairness_results}}. The fairness comparison chart can be found in \textbf{figure \ref{fig:Fairness_Comparison_Chart}}.

\begin{figure}[h]
    \centering
    \caption{Racial Disparities Among Iterations}
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/loan_grants_by_protected_attributes/initial.png}
        \caption{Initial Model Disparity}
        \label{fig:Initial_Disparity}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/loan_grants_by_protected_attributes/reweighted.png}
        \caption{Reweighed Model Disparity}
        \label{fig:Reweighed_Disparity}
    \end{minipage}
    
    \vspace{1em} 
    
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/loan_grants_by_protected_attributes/correlation_removed.png}
        \caption{Corr. Rem. Model Disparity}
        \label{fig:Correlation_Removed_Disparity}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/loan_grants_by_protected_attributes/calibrated_eqodds.png} 
        \caption{Cal. Eq. Odds Model Disparity}
        \label{fig:Calibrated_EqOdds_Disparity}
    \end{minipage}
    
    \label{fig:Racial_Disparities}
    \caption*{Apart from the Calibrated Equalized Odds model, which exhibits a higher amount of overall predicted grants, none of the iterations were able to substantially reduce the disparity in granted loans between races.}
\end{figure}

\begin{table}[h]
    \centering
    \caption{Model Performance and Fairness Comparison}
    \begin{tabular}{l *{4}{>{$}c<{$}}}
    \toprule
    & \textbf{Initial Model} & \textbf{Reweighing} & \textbf{Calibrated Equalized Odds} & \textbf{Correlation Removal} \\
    \midrule
    \textbf{accuracy} & 0.90 & 0.90 & 0.73 & \textbf{0.91} \\
    \textbf{precision} & 0.88 & 0.88 & 0.69 & \textbf{0.88} \\
    \textbf{recall} & \textbf{0.97} & 0.97 & 0.97 & 0.97 \\
    \textbf{f1} & 0.92 & 0.92 & 0.81 & \textbf{0.92} \\
    \textbf{roc\_auc} & \textbf{0.94} & 0.94 & \text{NA} & \text{NA} \\
    \midrule
    \textbf{tpr\_disparity} & 0.99 & \textbf{1.00} & 0.95 & 0.94 \\
    \textbf{fpr\_disparity} & 0.96 & \textbf{1.00} & 0.43 & 0.76 \\
    \textbf{tnr\_disparity} & 1.01 & \textbf{1.00} & 2.23 & 1.06 \\
    \textbf{fnr\_disparity} & 1.42 & \textbf{1.20} & 3.25 & 3.42 \\
    \bottomrule
    \end{tabular}
    \caption*{XXX Comment when ready XXX}
    \label{tab:model_performance_fairness_results}
\end{table}

\begin{table}[h]
    \centering
    \caption{Subgroup Fairness Assessment}
    \begin{tabular}{l *{4}{>{$}c<{$}}}
    \toprule
    & \textbf{Initial Model} & \textbf{Reweighing} & \textbf{Calibrated Equalized Odds} & \textbf{Correlation Removal} \\
    \midrule
    \textbf{Accuracy White} & 0.91 & 0.91 & 0.72 & \textbf{0.91} \\
    \textbf{Precision White} & \textbf{0.89} & 0.89 & 0.68 & 0.89 \\
    \textbf{Recall White} & 0.97 & 0.97 & \textbf{0.98} & 0.98 \\
    \textbf{F1 Score White} & 0.93 & 0.93 & 0.81 & \textbf{0.93} \\
    \textbf{AUC White} & \textbf{0.94} & 0.94 & \text{NA} & \text{NA} \\
    \midrule
    \textbf{Accuracy Black} & 0.88 & 0.88 & 0.81 & \textbf{0.88} \\
    \textbf{Precision Black} & 0.82 & 0.81 & 0.73 & 0.84 \\
    \textbf{Recall Black} & 0.96 & \textbf{0.97} & 0.93 & 0.92 \\
    \textbf{F1 Score Black} & \textbf{0.88} & 0.88 & 0.82 & 0.88 \\
    \textbf{AUC Black} & \textbf{0.95} & 0.95 & \text{NA} & \text{NA} \\
    \bottomrule
    \end{tabular}
    \caption*{XXX Comment when ready XXX}
    \label{tab:subgroup_fairness_results}
\end{table}

\begin{figure}
    \centering
    \caption{Fairness Comparison Chart}
    \includegraphics[width=0.85\textwidth]{images/CHXX_UPDATE_Results_Line.png}
    \caption*{While the initial model managed to put out values with a comparably high fairness as measured by disparities, reweighing managed to improve this overall performance. The other two models however did not manage to reach the same level of fairness.}
    \label{fig:Fairness_Comparison_Chart}
\end{figure}

% \section{Limitations}\label{sec:Limitations} - hier oder am Ende?